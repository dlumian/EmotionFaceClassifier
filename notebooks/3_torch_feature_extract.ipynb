{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fef806a-e66a-4cae-826b-c7063ac47c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "760e3287-ba77-4786-9492-cc4d40c44d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be2fbac-ef6a-4267-85c4-150dbf28f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec6b908-1ebc-4fd0-8826-9a46ff15551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c574d32d-1fd7-4192-88eb-6ad56a85e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df961b08-3ab9-43a9-86c7-4eab36d11b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a900e-9218-4e33-bc28-4d8487e7f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af621b82-e63d-488c-935f-f6108329186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascifuncs.tidbit_tools import load_json, write_json, print_json, check_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa4758d5-1ac5-419c-9c84-9548697118a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory set to /Users/dsl/Documents/GitHub/EmotionFaceClassifier, matches target dir string EmotionFaceClassifier.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dir = 'EmotionFaceClassifier'\n",
    "check_directory_name(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a0c365e-7441-46b0-8f0b-580bdfc0f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.decomposition_feature_extract import create_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4894c538-1926-4c08-9698-e44ac0cd5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dicts = load_json('./configs/input_mappings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5275fcd7-b417-4b4c-a458-a4f7e12fa8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_colors = common_dicts['plotly_styles']['Training']['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbf81980-4263-433f-9c59-75dddf91a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in FER 2013 data\n",
    "fer2013_path = 'data/fer2013_paths.csv'\n",
    "fer2013 = pd.read_csv(fer2013_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3246ab7-92ed-43a3-ba6d-6c1bc14dd9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "      <th>emotion</th>\n",
       "      <th>image</th>\n",
       "      <th>usage</th>\n",
       "      <th>emo_count_id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Angry</td>\n",
       "      <td>[[ 70  80  82 ...  52  43  41]\\n [ 65  61  58 ...</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>data/Training/Angry/Angry-1.jpg</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Angry</td>\n",
       "      <td>[[151 150 147 ... 129 140 120]\\n [151 149 149 ...</td>\n",
       "      <td>Training</td>\n",
       "      <td>2</td>\n",
       "      <td>data/Training/Angry/Angry-2.jpg</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Fear</td>\n",
       "      <td>[[231 212 156 ...  44  27  16]\\n [229 175 148 ...</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>data/Training/Fear/Fear-1.jpg</td>\n",
       "      <td>slategray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[[ 24  32  36 ... 173 172 173]\\n [ 25  34  29 ...</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>data/Training/Sad/Sad-1.jpg</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[[ 4  0  0 ... 27 24 25]\\n [ 1  0  0 ... 26 23...</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>data/Training/Neutral/Neutral-1.jpg</td>\n",
       "      <td>sienna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion_id                                             pixels     Usage  \\\n",
       "0           0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training   \n",
       "1           0  151 150 147 155 148 133 111 140 170 174 182 15...  Training   \n",
       "2           2  231 212 156 164 174 138 161 173 182 200 106 38...  Training   \n",
       "3           4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training   \n",
       "4           6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training   \n",
       "\n",
       "   emotion                                              image     usage  \\\n",
       "0    Angry  [[ 70  80  82 ...  52  43  41]\\n [ 65  61  58 ...  Training   \n",
       "1    Angry  [[151 150 147 ... 129 140 120]\\n [151 149 149 ...  Training   \n",
       "2     Fear  [[231 212 156 ...  44  27  16]\\n [229 175 148 ...  Training   \n",
       "3      Sad  [[ 24  32  36 ... 173 172 173]\\n [ 25  34  29 ...  Training   \n",
       "4  Neutral  [[ 4  0  0 ... 27 24 25]\\n [ 1  0  0 ... 26 23...  Training   \n",
       "\n",
       "   emo_count_id                             img_path      color  \n",
       "0             1      data/Training/Angry/Angry-1.jpg        red  \n",
       "1             2      data/Training/Angry/Angry-2.jpg        red  \n",
       "2             1        data/Training/Fear/Fear-1.jpg  slategray  \n",
       "3             1          data/Training/Sad/Sad-1.jpg       blue  \n",
       "4             1  data/Training/Neutral/Neutral-1.jpg     sienna  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fer2013.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2c9306b-ce37-437c-8eb3-8eb91f0a283c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35887, 9)\n",
      "(28709, 9)\n"
     ]
    }
   ],
   "source": [
    "# Select training data\n",
    "print(fer2013.shape)\n",
    "train_df = fer2013[fer2013['usage']=='Training']\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3306ec1f-5a9a-43ea-b53f-3558b2130fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Angry', 'Fear', 'Sad', 'Neutral', 'Happy', 'Surprise', 'Disgust'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4fc7a7e-0669-4f4c-bff1-1c76d9fd28bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_X_y(train_df, 'img_path', 'emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4df5c-a2d4-41e4-ac5b-dea8686110e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a62da-2e67-41cc-8041-2479c16613ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume X and y are loaded as numpy arrays\n",
    "X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y = torch.tensor(y).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed1b119-4218-431e-8616-70ce3c125056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA(nn.Module):\n",
    "    def __init__(self, n_components):\n",
    "        super().__init__()\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean_ = torch.mean(X, dim=0)\n",
    "        X_centered = X - self.mean_\n",
    "        U, S, V = torch.pca_lowrank(X_centered, q=self.n_components)\n",
    "        self.components_ = V.T\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_centered = X - self.mean_\n",
    "        return torch.matmul(X_centered, self.components_.T)\n",
    "\n",
    "    def inverse_transform(self, X_transformed):\n",
    "        return torch.matmul(X_transformed, self.components_) + self.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d00bbac-55ed-4112-9797-9be0dc6efd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(X_true, X_pred):\n",
    "    X_true_np = X_true.cpu().numpy()\n",
    "    X_pred_np = X_pred.cpu().numpy()\n",
    "    \n",
    "    mse = mean_squared_error(X_true_np, X_pred_np)\n",
    "    psnr = 10 * np.log10((255**2) / mse)  # Assuming pixel values are in [0, 255]\n",
    "    \n",
    "    # Reshape if necessary (assuming images are square)\n",
    "    img_size = int(np.sqrt(X_true_np.shape[1]))\n",
    "    X_true_2d = X_true_np.reshape(-1, img_size, img_size)\n",
    "    X_pred_2d = X_pred_np.reshape(-1, img_size, img_size)\n",
    "    \n",
    "    ssim_value = ssim(X_true_2d, X_pred_2d, \n",
    "                      data_range=X_true_2d.max() - X_true_2d.min(), \n",
    "                      multichannel=True)\n",
    "    \n",
    "    return {\n",
    "        'MSE': mse,\n",
    "        'PSNR': psnr,\n",
    "        'SSIM': ssim_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a73b31-35ef-44a5-b735-e14043d0aa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_analysis(X, y, analysis_config):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    logging.info(\"Starting analysis\")\n",
    "\n",
    "    # Check for GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "\n",
    "    \n",
    "    n_components = analysis_config['total_components']\n",
    "    model = PCA(n_components).to(device)\n",
    "\n",
    "    logging.info(\"Fitting PCA model\")\n",
    "    model.fit(X)\n",
    "    \n",
    "    logging.info(\"Transforming data\")\n",
    "    features = model.transform(X)\n",
    "\n",
    "    results = []\n",
    "    for category in torch.unique(y):\n",
    "        X_category = X[y == category]\n",
    "        features_category = features[y == category]\n",
    "\n",
    "        for recon_components in analysis_config['components_for_reconstruction']:\n",
    "            logging.info(f\"Processing category {category.item()} with {recon_components} components\")\n",
    "            \n",
    "            partial_features = torch.zeros_like(features_category)\n",
    "            partial_features[:, :recon_components] = features_category[:, :recon_components]\n",
    "            \n",
    "            recon_images = model.inverse_transform(partial_features)\n",
    "            avg_image = torch.mean(recon_images, dim=0)\n",
    "\n",
    "            metrics = calculate_metrics(X_category, recon_images)\n",
    "\n",
    "            results.append({\n",
    "                'category': category.item(),\n",
    "                'components': recon_components,\n",
    "                'avg_image': avg_image.cpu().numpy(),\n",
    "                'metrics': metrics\n",
    "            })\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    logging.info(f\"Analysis completed in {total_time:.2f} seconds\")\n",
    "\n",
    "    return results, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a003a-90fc-4d9c-8211-736f39c5d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_config = {\n",
    "    'total_components': 100,\n",
    "    'components_for_reconstruction': [1, 10, 30, 50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743695b2-f86f-429b-9fe4-d949ecc3c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, total_time = run_single_analysis(X, y, analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c74f67a-634b-4aa1-844f-e78a0a45172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results\n",
    "save_dir = os.path.join('models', 'unsupervised')\n",
    "os.makedirs(save_dir, exists_ok=True)\n",
    "save_file_name = 'pca_results.pt'\n",
    "save_path = os.path.join(save_dir, save_file_name)\n",
    "torch.save({\n",
    "    'results': results,\n",
    "    'total_time': total_time,\n",
    "    'config': analysis_config\n",
    "}, save_path)\n",
    "logging.info(f\"Results saved to {save_path}\")\n",
    "\n",
    "# If you prefer numpy compressed format:\n",
    "npz_file_name = 'pca_results.npz'\n",
    "npz_save_path = os.path.join(save_dir, npz_file_name)\n",
    "np_results = np.array(results, dtype=object)\n",
    "np.savez_compressed(npz_save_path, results=np_results, total_time=total_time, config=analysis_config)\n",
    "logging.info(\"Results also saved in numpy compressed format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08050ad-da53-475e-ac98-1692cc427165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c778aa-2964-462b-9483-a71b07e5b0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3af812-20f0-4205-b6e0-f379b3f41620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8ea8779-d3fa-454f-9219-6dae447b3254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
