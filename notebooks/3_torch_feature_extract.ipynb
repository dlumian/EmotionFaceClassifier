{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fef806a-e66a-4cae-826b-c7063ac47c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "760e3287-ba77-4786-9492-cc4d40c44d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be2fbac-ef6a-4267-85c4-150dbf28f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec6b908-1ebc-4fd0-8826-9a46ff15551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c574d32d-1fd7-4192-88eb-6ad56a85e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df961b08-3ab9-43a9-86c7-4eab36d11b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e3a900e-9218-4e33-bc28-4d8487e7f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af621b82-e63d-488c-935f-f6108329186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascifuncs.tidbit_tools import load_json, write_json, print_json, check_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa4758d5-1ac5-419c-9c84-9548697118a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory set to /home/dsl/Documents/GitHub/EmotionFaceClassifier, matches target dir string EmotionFaceClassifier.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dir = 'EmotionFaceClassifier'\n",
    "check_directory_name(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a0c365e-7441-46b0-8f0b-580bdfc0f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.decomposition_feature_extract import create_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4894c538-1926-4c08-9698-e44ac0cd5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dicts = load_json('./configs/input_mappings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5275fcd7-b417-4b4c-a458-a4f7e12fa8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_colors = common_dicts['plotly_styles']['Training']['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbf81980-4263-433f-9c59-75dddf91a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in FER 2013 data\n",
    "fer2013_path = 'data/fer2013_paths.csv'\n",
    "fer2013 = pd.read_csv(fer2013_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3246ab7-92ed-43a3-ba6d-6c1bc14dd9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "      <th>emotion</th>\n",
       "      <th>image</th>\n",
       "      <th>usage</th>\n",
       "      <th>emo_count_id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Angry</td>\n",
       "      <td>[[ 70  80  82 ...  52  43  41]\\n [ 65  61  58 ...</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>data/Training/Angry/Angry-1.jpg</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Angry</td>\n",
       "      <td>[[151 150 147 ... 129 140 120]\\n [151 149 149 ...</td>\n",
       "      <td>Training</td>\n",
       "      <td>2</td>\n",
       "      <td>data/Training/Angry/Angry-2.jpg</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Fear</td>\n",
       "      <td>[[231 212 156 ...  44  27  16]\\n [229 175 148 ...</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>data/Training/Fear/Fear-1.jpg</td>\n",
       "      <td>slategray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[[ 24  32  36 ... 173 172 173]\\n [ 25  34  29 ...</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>data/Training/Sad/Sad-1.jpg</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[[ 4  0  0 ... 27 24 25]\\n [ 1  0  0 ... 26 23...</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>data/Training/Neutral/Neutral-1.jpg</td>\n",
       "      <td>sienna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion_id                                             pixels     Usage  \\\n",
       "0           0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training   \n",
       "1           0  151 150 147 155 148 133 111 140 170 174 182 15...  Training   \n",
       "2           2  231 212 156 164 174 138 161 173 182 200 106 38...  Training   \n",
       "3           4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training   \n",
       "4           6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training   \n",
       "\n",
       "   emotion                                              image     usage  \\\n",
       "0    Angry  [[ 70  80  82 ...  52  43  41]\\n [ 65  61  58 ...  Training   \n",
       "1    Angry  [[151 150 147 ... 129 140 120]\\n [151 149 149 ...  Training   \n",
       "2     Fear  [[231 212 156 ...  44  27  16]\\n [229 175 148 ...  Training   \n",
       "3      Sad  [[ 24  32  36 ... 173 172 173]\\n [ 25  34  29 ...  Training   \n",
       "4  Neutral  [[ 4  0  0 ... 27 24 25]\\n [ 1  0  0 ... 26 23...  Training   \n",
       "\n",
       "   emo_count_id                             img_path      color  \n",
       "0             1      data/Training/Angry/Angry-1.jpg        red  \n",
       "1             2      data/Training/Angry/Angry-2.jpg        red  \n",
       "2             1        data/Training/Fear/Fear-1.jpg  slategray  \n",
       "3             1          data/Training/Sad/Sad-1.jpg       blue  \n",
       "4             1  data/Training/Neutral/Neutral-1.jpg     sienna  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fer2013.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2c9306b-ce37-437c-8eb3-8eb91f0a283c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35887, 9)\n",
      "(28709, 9)\n"
     ]
    }
   ],
   "source": [
    "# Select training data\n",
    "print(fer2013.shape)\n",
    "train_df = fer2013[fer2013['usage']=='Training']\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3306ec1f-5a9a-43ea-b53f-3558b2130fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Angry', 'Fear', 'Sad', 'Neutral', 'Happy', 'Surprise', 'Disgust'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4fc7a7e-0669-4f4c-bff1-1c76d9fd28bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_X_y(train_df, 'img_path', 'emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4285d029-69a5-4a93-97b6-6a1d2589730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'y' is your array of string labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca58f97b-cdf9-44a2-a931-73a03d7415c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results\n",
    "save_dir = os.path.join('models', 'unsupervised')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_file_name = 'pca_results.pt'\n",
    "save_path = os.path.join(save_dir, save_file_name)\n",
    "npz_file_name = 'pca_results.npz'\n",
    "npz_save_path = os.path.join(save_dir, npz_file_name)\n",
    "\n",
    "log_path = os.path.join(save_dir, 'analysis.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abfaed78-dc01-4523-80f1-b2dc99375a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_path),\n",
    "        logging.StreamHandler()  # This will also print logs to console\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1be4df5c-a2d4-41e4-ac5b-dea8686110e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6808696a-9ebf-4a86-abdf-c8d951e7ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "949a62da-2e67-41cc-8041-2479c16613ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume X and y are loaded as numpy arrays\n",
    "X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "# Convert to PyTorch tensor\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eed1b119-4218-431e-8616-70ce3c125056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA(nn.Module):\n",
    "    def __init__(self, n_components):\n",
    "        super().__init__()\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean_ = torch.mean(X, dim=0)\n",
    "        X_centered = X - self.mean_\n",
    "        U, S, V = torch.pca_lowrank(X_centered, q=self.n_components)\n",
    "        self.components_ = V.T\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_centered = X - self.mean_\n",
    "        return torch.matmul(X_centered, self.components_.T)\n",
    "\n",
    "    def inverse_transform(self, X_transformed):\n",
    "        return torch.matmul(X_transformed, self.components_) + self.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d00bbac-55ed-4112-9797-9be0dc6efd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(X_true, X_pred):\n",
    "    X_true_np = X_true.cpu().numpy()\n",
    "    X_pred_np = X_pred.cpu().numpy()\n",
    "    \n",
    "    mse = mean_squared_error(X_true_np, X_pred_np)\n",
    "    psnr = 10 * np.log10((255**2) / mse)  # Assuming pixel values are in [0, 255]\n",
    "    \n",
    "    # Reshape if necessary (assuming images are square)\n",
    "    img_size = int(np.sqrt(X_true_np.shape[1]))\n",
    "    X_true_2d = X_true_np.reshape(-1, img_size, img_size)\n",
    "    X_pred_2d = X_pred_np.reshape(-1, img_size, img_size)\n",
    "    \n",
    "    ssim_value = ssim(X_true_2d, X_pred_2d, \n",
    "                      data_range=X_true_2d.max() - X_true_2d.min(), \n",
    "                      multichannel=True)\n",
    "    \n",
    "    return {\n",
    "        'MSE': mse,\n",
    "        'PSNR': psnr,\n",
    "        'SSIM': ssim_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24a73b31-35ef-44a5-b735-e14043d0aa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_analysis(X, y, analysis_config, device):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    logging.info(\"Starting analysis\")\n",
    "\n",
    "    # Check for GPU\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "\n",
    "    \n",
    "    n_components = analysis_config['total_components']\n",
    "    model = PCA(n_components).to(device)\n",
    "\n",
    "    logging.info(\"Fitting PCA model\")\n",
    "    model.fit(X)\n",
    "    \n",
    "    logging.info(\"Transforming data\")\n",
    "    features = model.transform(X)\n",
    "\n",
    "    results = []\n",
    "    for category in torch.unique(y):\n",
    "        X_category = X[y == category]\n",
    "        features_category = features[y == category]\n",
    "\n",
    "        for recon_components in analysis_config['components_for_reconstruction']:\n",
    "            logging.info(f\"Processing category {category.item()} with {recon_components} components\")\n",
    "            \n",
    "            partial_features = torch.zeros_like(features_category)\n",
    "            partial_features[:, :recon_components] = features_category[:, :recon_components]\n",
    "            \n",
    "            recon_images = model.inverse_transform(partial_features)\n",
    "            avg_image = torch.mean(recon_images, dim=0)\n",
    "\n",
    "            metrics = calculate_metrics(X_category, recon_images)\n",
    "\n",
    "            results.append({\n",
    "                'category': category.item(),\n",
    "                'components': recon_components,\n",
    "                'avg_image': avg_image.cpu().numpy(),\n",
    "                'metrics': metrics\n",
    "            })\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    logging.info(f\"Analysis completed in {total_time:.2f} seconds\")\n",
    "\n",
    "    return results, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "444a003a-90fc-4d9c-8211-736f39c5d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_config = {\n",
    "    'total_components': 100,\n",
    "    'components_for_reconstruction': [1, 10, 30, 50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "743695b2-f86f-429b-9fe4-d949ecc3c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:47:23,523 - root - INFO - Starting analysis\n",
      "2024-11-19 14:47:23,524 - root - INFO - Using device: cuda\n",
      "2024-11-19 14:47:23,524 - root - INFO - Fitting PCA model\n",
      "2024-11-19 14:47:23,654 - root - INFO - Transforming data\n",
      "2024-11-19 14:47:23,676 - root - INFO - Processing category 0 with 1 components\n",
      "2024-11-19 14:47:24,648 - root - INFO - Processing category 0 with 10 components\n",
      "2024-11-19 14:47:25,591 - root - INFO - Processing category 0 with 30 components\n",
      "2024-11-19 14:47:26,533 - root - INFO - Processing category 0 with 50 components\n",
      "2024-11-19 14:47:27,485 - root - INFO - Processing category 0 with 100 components\n",
      "2024-11-19 14:47:28,424 - root - INFO - Processing category 1 with 1 components\n",
      "2024-11-19 14:47:28,519 - root - INFO - Processing category 1 with 10 components\n",
      "2024-11-19 14:47:28,614 - root - INFO - Processing category 1 with 30 components\n",
      "2024-11-19 14:47:28,705 - root - INFO - Processing category 1 with 50 components\n",
      "2024-11-19 14:47:28,793 - root - INFO - Processing category 1 with 100 components\n",
      "2024-11-19 14:47:28,883 - root - INFO - Processing category 2 with 1 components\n",
      "2024-11-19 14:47:29,852 - root - INFO - Processing category 2 with 10 components\n",
      "2024-11-19 14:47:30,814 - root - INFO - Processing category 2 with 30 components\n",
      "2024-11-19 14:47:31,788 - root - INFO - Processing category 2 with 50 components\n",
      "2024-11-19 14:47:32,742 - root - INFO - Processing category 2 with 100 components\n",
      "2024-11-19 14:47:33,710 - root - INFO - Processing category 3 with 1 components\n",
      "2024-11-19 14:47:35,594 - root - INFO - Processing category 3 with 10 components\n",
      "2024-11-19 14:47:37,493 - root - INFO - Processing category 3 with 30 components\n",
      "2024-11-19 14:47:39,383 - root - INFO - Processing category 3 with 50 components\n",
      "2024-11-19 14:47:41,257 - root - INFO - Processing category 3 with 100 components\n",
      "2024-11-19 14:47:43,156 - root - INFO - Processing category 4 with 1 components\n",
      "2024-11-19 14:47:44,363 - root - INFO - Processing category 4 with 10 components\n",
      "2024-11-19 14:47:45,581 - root - INFO - Processing category 4 with 30 components\n",
      "2024-11-19 14:47:46,810 - root - INFO - Processing category 4 with 50 components\n",
      "2024-11-19 14:47:48,031 - root - INFO - Processing category 4 with 100 components\n",
      "2024-11-19 14:47:49,249 - root - INFO - Processing category 5 with 1 components\n",
      "2024-11-19 14:47:50,421 - root - INFO - Processing category 5 with 10 components\n",
      "2024-11-19 14:47:51,595 - root - INFO - Processing category 5 with 30 components\n",
      "2024-11-19 14:47:52,770 - root - INFO - Processing category 5 with 50 components\n",
      "2024-11-19 14:47:53,953 - root - INFO - Processing category 5 with 100 components\n",
      "2024-11-19 14:47:55,122 - root - INFO - Processing category 6 with 1 components\n",
      "2024-11-19 14:47:55,834 - root - INFO - Processing category 6 with 10 components\n",
      "2024-11-19 14:47:56,519 - root - INFO - Processing category 6 with 30 components\n",
      "2024-11-19 14:47:57,203 - root - INFO - Processing category 6 with 50 components\n",
      "2024-11-19 14:47:57,855 - root - INFO - Processing category 6 with 100 components\n",
      "2024-11-19 14:47:58,510 - root - INFO - Analysis completed in 34.99 seconds\n"
     ]
    }
   ],
   "source": [
    "results, total_time = run_single_analysis(X, y_tensor, analysis_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c74f67a-634b-4aa1-844f-e78a0a45172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:47:58,559 - root - INFO - Results saved to models/unsupervised/pca_results.pt\n",
      "2024-11-19 14:47:58,577 - root - INFO - Results also saved in numpy compressed format\n"
     ]
    }
   ],
   "source": [
    "np_results = np.array(results, dtype=object)\n",
    "torch.save({\n",
    "    'results': results,\n",
    "    'total_time': total_time,\n",
    "    'config': analysis_config\n",
    "}, save_path)\n",
    "logging.info(f\"Results saved to {save_path}\")\n",
    "\n",
    "np.savez_compressed(npz_save_path, results=np_results, total_time=total_time, config=analysis_config)\n",
    "logging.info(\"Results also saved in numpy compressed format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f08050ad-da53-475e-ac98-1692cc427165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51c778aa-2964-462b-9483-a71b07e5b0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'avg_image': array([116.96735 , 113.89587 , 110.902534, ..., 109.56157 , 110.38948 ,\n",
      "       111.18796 ], dtype=float32),\n",
      "  'category': 0,\n",
      "  'components': 1,\n",
      "  'metrics': {'MSE': 2932.914,\n",
      "              'PSNR': 13.457810229909459,\n",
      "              'SSIM': 0.39912117729735686}},\n",
      " {'avg_image': array([117.5271  , 114.932594, 112.44693 , ..., 108.00855 , 108.776245,\n",
      "       109.520645], dtype=float32),\n",
      "  'category': 0,\n",
      "  'components': 10,\n",
      "  'metrics': {'MSE': 1382.6038,\n",
      "              'PSNR': 16.72382627326816,\n",
      "              'SSIM': 0.721695368897709}},\n",
      " {'avg_image': array([117.88055, 115.28519, 112.83915, ..., 106.85682, 107.76051,\n",
      "       108.62382], dtype=float32),\n",
      "  'category': 0,\n",
      "  'components': 30,\n",
      "  'metrics': {'MSE': 865.10583,\n",
      "              'PSNR': 18.76011119613641,\n",
      "              'SSIM': 0.8292056184303512}},\n",
      " {'avg_image': array([116.78597 , 114.374146, 112.29136 , ..., 107.30511 , 108.20918 ,\n",
      "       109.031166], dtype=float32),\n",
      "  'category': 0,\n",
      "  'components': 50,\n",
      "  'metrics': {'MSE': 660.08136,\n",
      "              'PSNR': 19.93482892050305,\n",
      "              'SSIM': 0.8731010064008603}},\n",
      " {'avg_image': array([116.143105, 113.79902 , 112.0364  , ..., 107.42273 , 108.35079 ,\n",
      "       109.19638 ], dtype=float32),\n",
      "  'category': 0,\n",
      "  'components': 100,\n",
      "  'metrics': {'MSE': 445.76166,\n",
      "              'PSNR': 21.639776510507488,\n",
      "              'SSIM': 0.9170273831370268}},\n",
      " {'avg_image': array([126.870186, 123.703064, 120.698906, ..., 118.97232 , 119.83493 ,\n",
      "       120.64185 ], dtype=float32),\n",
      "  'category': 1,\n",
      "  'components': 1,\n",
      "  'metrics': {'MSE': 2599.4683,\n",
      "              'PSNR': 13.981958415966995,\n",
      "              'SSIM': 0.43488561924135927}},\n",
      " {'avg_image': array([115.60403 , 112.25141 , 109.230896, ..., 113.51659 , 113.73729 ,\n",
      "       114.37254 ], dtype=float32),\n",
      "  'category': 1,\n",
      "  'components': 10,\n",
      "  'metrics': {'MSE': 1152.7123,\n",
      "              'PSNR': 17.513594409824282,\n",
      "              'SSIM': 0.7450212257231089}},\n",
      " {'avg_image': array([110.72292, 106.60903, 103.34908, ..., 111.84665, 112.23747,\n",
      "       113.25865], dtype=float32),\n",
      "  'category': 1,\n",
      "  'components': 30,\n",
      "  'metrics': {'MSE': 717.1618,\n",
      "              'PSNR': 19.57463209742468,\n",
      "              'SSIM': 0.840861333861683}},\n",
      " {'avg_image': array([108.69568 , 104.791435, 102.05241 , ..., 110.29954 , 110.83735 ,\n",
      "       112.09929 ], dtype=float32),\n",
      "  'category': 1,\n",
      "  'components': 50,\n",
      "  'metrics': {'MSE': 541.74286,\n",
      "              'PSNR': 20.792871655950826,\n",
      "              'SSIM': 0.8827482684351527}},\n",
      " {'avg_image': array([109.51734 , 105.16097 , 101.428085, ..., 108.34484 , 108.184555,\n",
      "       109.1749  ], dtype=float32),\n",
      "  'category': 1,\n",
      "  'components': 100,\n",
      "  'metrics': {'MSE': 361.9414,\n",
      "              'PSNR': 22.544420914451244,\n",
      "              'SSIM': 0.9239644050827599}},\n",
      " {'avg_image': array([127.7479  , 124.57231 , 121.56719 , ..., 119.80643 , 120.672104,\n",
      "       121.47978 ], dtype=float32),\n",
      "  'category': 2,\n",
      "  'components': 1,\n",
      "  'metrics': {'MSE': 2941.8188,\n",
      "              'PSNR': 13.444644347896267,\n",
      "              'SSIM': 0.39163269252086885}},\n",
      " {'avg_image': array([128.94682 , 125.85211 , 122.89847 , ..., 119.84915 , 120.714745,\n",
      "       121.535286], dtype=float32),\n",
      "  'category': 2,\n",
      "  'components': 10,\n",
      "  'metrics': {'MSE': 1435.3148,\n",
      "              'PSNR': 16.561331919896286,\n",
      "              'SSIM': 0.7068275990549264}},\n",
      " {'avg_image': array([129.29317 , 126.26176 , 123.34731 , ..., 120.10959 , 120.939255,\n",
      "       121.741516], dtype=float32),\n",
      "  'category': 2,\n",
      "  'components': 30,\n",
      "  'metrics': {'MSE': 883.202,\n",
      "              'PSNR': 18.670203040617288,\n",
      "              'SSIM': 0.822659175345864}},\n",
      " {'avg_image': array([130.34175 , 127.202324, 124.0069  , ..., 119.57503 , 120.35671 ,\n",
      "       121.199684], dtype=float32),\n",
      "  'category': 2,\n",
      "  'components': 50,\n",
      "  'metrics': {'MSE': 675.5852,\n",
      "              'PSNR': 19.834002306605996,\n",
      "              'SSIM': 0.867980065871809}},\n",
      " {'avg_image': array([130.15565 , 127.06674 , 123.9634  , ..., 119.479454, 120.22771 ,\n",
      "       121.03634 ], dtype=float32),\n",
      "  'category': 2,\n",
      "  'components': 100,\n",
      "  'metrics': {'MSE': 460.1294,\n",
      "              'PSNR': 21.502003826021387,\n",
      "              'SSIM': 0.9123643912979434}},\n",
      " {'avg_image': array([119.48473, 116.38895, 113.39287, ..., 111.95387, 112.7906 ,\n",
      "       113.59123], dtype=float32),\n",
      "  'category': 3,\n",
      "  'components': 1,\n",
      "  'metrics': {'MSE': 2683.669,\n",
      "              'PSNR': 13.84351420194953,\n",
      "              'SSIM': 0.40836170824757967}},\n",
      " {'avg_image': array([119.031944, 116.1532  , 113.38673 , ..., 110.76247 , 111.54956 ,\n",
      "       112.33129 ], dtype=float32),\n",
      "  'category': 3,\n",
      "  'components': 10,\n",
      "  'metrics': {'MSE': 1250.1202,\n",
      "              'PSNR': 17.161285744720015,\n",
      "              'SSIM': 0.72872939261484}},\n",
      " {'avg_image': array([119.76841 , 116.927216, 114.00245 , ..., 109.12418 , 110.01957 ,\n",
      "       110.86779 ], dtype=float32),\n",
      "  'category': 3,\n",
      "  'components': 30,\n",
      "  'metrics': {'MSE': 774.8888,\n",
      "              'PSNR': 19.23840980479389,\n",
      "              'SSIM': 0.8316292722031395}},\n",
      " {'avg_image': array([118.49273, 115.64098, 112.84594, ..., 109.25361, 110.19756,\n",
      "       111.11521], dtype=float32),\n",
      "  'category': 3,\n",
      "  'components': 50,\n",
      "  'metrics': {'MSE': 593.2129,\n",
      "              'PSNR': 20.398697811102192,\n",
      "              'SSIM': 0.8736474165856531}},\n",
      " {'avg_image': array([119.09335 , 116.26707 , 113.43553 , ..., 109.432724, 110.28574 ,\n",
      "       111.2035  ], dtype=float32),\n",
      "  'category': 3,\n",
      "  'components': 100,\n",
      "  'metrics': {'MSE': 397.37387,\n",
      "              'PSNR': 22.138810540047995,\n",
      "              'SSIM': 0.9179958748145048}},\n",
      " {'avg_image': array([113.38067 , 110.34382 , 107.35443 , ..., 106.153114, 106.96845 ,\n",
      "       107.76387 ], dtype=float32),\n",
      "  'category': 4,\n",
      "  'components': 1,\n",
      "  'metrics': {'MSE': 2842.6238,\n",
      "              'PSNR': 13.593609761641808,\n",
      "              'SSIM': 0.41509385083301054}},\n",
      " {'avg_image': array([112.88788, 109.00755, 105.12438, ..., 107.56296, 108.53771,\n",
      "       109.47358], dtype=float32),\n",
      "  'category': 4,\n",
      "  'components': 10,\n",
      "  'metrics': {'MSE': 1245.7808,\n",
      "              'PSNR': 17.176387409792508,\n",
      "              'SSIM': 0.7545076996362529}},\n",
      " {'avg_image': array([108.48741 , 104.64771 , 101.020775, ..., 109.830185, 110.74237 ,\n",
      "       111.57271 ], dtype=float32),\n",
      "  'category': 4,\n",
      "  'components': 30,\n",
      "  'metrics': {'MSE': 759.20917,\n",
      "              'PSNR': 19.327189172941132,\n",
      "              'SSIM': 0.8518586084830303}},\n",
      " {'avg_image': array([110.02704 , 105.99172 , 101.985435, ..., 109.916885, 111.07261 ,\n",
      "       112.04303 ], dtype=float32),\n",
      "  'category': 4,\n",
      "  'components': 50,\n",
      "  'metrics': {'MSE': 576.86523,\n",
      "              'PSNR': 20.52005994511702,\n",
      "              'SSIM': 0.8900890161160359}},\n",
      " {'avg_image': array([109.31015 , 105.41986 , 101.550766, ..., 110.17377 , 111.27727 ,\n",
      "       112.12752 ], dtype=float32),\n",
      "  'category': 4,\n",
      "  'components': 100,\n",
      "  'metrics': {'MSE': 383.93353,\n",
      "              'PSNR': 22.288243158590426,\n",
      "              'SSIM': 0.9291305477839665}},\n",
      " {'avg_image': array([111.06553 , 108.05104 , 105.064186, ..., 103.95302 , 104.760254,\n",
      "       105.5537  ], dtype=float32),\n",
      "  'category': 5,\n",
      "  'components': 1,\n",
      "  'metrics': {'MSE': 2891.7283,\n",
      "              'PSNR': 13.519228799007767,\n",
      "              'SSIM': 0.40113375556508557}},\n",
      " {'avg_image': array([111.915764, 109.674675, 107.51655 , ..., 104.691734, 105.37267 ,\n",
      "       105.98775 ], dtype=float32),\n",
      "  'category': 5,\n",
      "  'components': 10,\n",
      "  'metrics': {'MSE': 1364.076,\n",
      "              'PSNR': 16.7824177713849,\n",
      "              'SSIM': 0.7241386746353207}},\n",
      " {'avg_image': array([108.9675  , 106.91733 , 104.974144, ..., 104.69133 , 105.0145  ,\n",
      "       105.37707 ], dtype=float32),\n",
      "  'category': 5,\n",
      "  'components': 30,\n",
      "  'metrics': {'MSE': 821.60406,\n",
      "              'PSNR': 18.984177815721953,\n",
      "              'SSIM': 0.8380214041519465}},\n",
      " {'avg_image': array([108.64095 , 106.688286, 104.94737 , ..., 105.6809  , 106.029274,\n",
      "       106.32087 ], dtype=float32),\n",
      "  'category': 5,\n",
      "  'components': 50,\n",
      "  'metrics': {'MSE': 616.6671,\n",
      "              'PSNR': 20.23029571963541,\n",
      "              'SSIM': 0.8823504938119733}},\n",
      " {'avg_image': array([108.273575, 106.29915 , 104.52907 , ..., 105.39861 , 105.79495 ,\n",
      "       106.09274 ], dtype=float32),\n",
      "  'category': 5,\n",
      "  'components': 100,\n",
      "  'metrics': {'MSE': 410.90543,\n",
      "              'PSNR': 21.993384846892052,\n",
      "              'SSIM': 0.924209817403348}},\n",
      " {'avg_image': array([139.93536, 136.64207, 133.62361, ..., 131.38826, 132.29665,\n",
      "       133.11472], dtype=float32),\n",
      "  'category': 6,\n",
      "  'components': 1,\n",
      "  'metrics': {'MSE': 2859.909,\n",
      "              'PSNR': 13.56728156207096,\n",
      "              'SSIM': 0.39178569666801943}},\n",
      " {'avg_image': array([139.73694, 135.41252, 131.30492, ..., 133.41797, 134.54626,\n",
      "       135.53421], dtype=float32),\n",
      "  'category': 6,\n",
      "  'components': 10,\n",
      "  'metrics': {'MSE': 1400.3856,\n",
      "              'PSNR': 16.668327183120617,\n",
      "              'SSIM': 0.6993389012140024}},\n",
      " {'avg_image': array([149.22035, 144.48007, 139.9364 , ..., 134.94038, 136.31688,\n",
      "       137.52414], dtype=float32),\n",
      "  'category': 6,\n",
      "  'components': 30,\n",
      "  'metrics': {'MSE': 855.5957,\n",
      "              'PSNR': 18.80811766027078,\n",
      "              'SSIM': 0.8177824498431425}},\n",
      " {'avg_image': array([150.51262, 145.8336 , 141.11441, ..., 133.34143, 134.22905,\n",
      "       135.13347], dtype=float32),\n",
      "  'category': 6,\n",
      "  'components': 50,\n",
      "  'metrics': {'MSE': 657.16284,\n",
      "              'PSNR': 19.954073618851712,\n",
      "              'SSIM': 0.862841207271124}},\n",
      " {'avg_image': array([151.76543, 146.74614, 141.55388, ..., 133.20572, 134.41788,\n",
      "       135.55275], dtype=float32),\n",
      "  'category': 6,\n",
      "  'components': 100,\n",
      "  'metrics': {'MSE': 448.17496,\n",
      "              'PSNR': 21.61632775114565,\n",
      "              'SSIM': 0.9079878559633159}}]\n"
     ]
    }
   ],
   "source": [
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3af812-20f0-4205-b6e0-f379b3f41620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea8779-d3fa-454f-9219-6dae447b3254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
