{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df4f9c7-8cff-4c1e-afcf-b99859f985b6",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Emotion Face Classifier Notebook 1\n",
    "\n",
    "Reads initial csv data in and generates images by usage (train/test) and emotion category.\n",
    "\n",
    "Pixel data is stored in a single column and imported as a string, so conversion to a 2D matrix is needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf73d2-366b-44f8-9665-3e58e05094ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9b3bf-1f39-499b-b436-85f46fab889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77afd9cc-6be2-45f5-b1ea-f8654c2c93c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascifuncs.tidbit_tools import load_json, print_json, check_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe08d11-e2c1-4afb-8d08-00e70c7c0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure working directory for correct filepaths\n",
    "main_dir = 'EmotionFaceClassifier'\n",
    "check_directory_name(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176bfac-ea21-4910-97f0-ec5f694d276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import (\n",
    "    convert_pixels_to_array,\n",
    "    save_image\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abdf265-69f5-42b8-8ed8-fe83865b997a",
   "metadata": {},
   "source": [
    "### Import and Check Details\n",
    "\n",
    "Imports settings from json and displays relevant sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c054caa-846a-493b-a070-70c1d442f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load common dicts from json config file\n",
    "common_dicts = load_json('./configs/input_mappings.json')\n",
    "print_json(common_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a523b6-ff00-400e-b097-c8ff53259c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select emotion mapping section of json\n",
    "emo_dict = common_dicts['emo_dict']\n",
    "print_json(emo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d93b64-4b4d-40dc-8bf8-56155a6aeede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select color mappings for emotion categories\n",
    "emo_color_dict = common_dicts['color_dict']\n",
    "print_json(emo_color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dd0927-5970-44fd-a490-63ef15defe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get set order to display results\n",
    "category_order = common_dicts['category_order']\n",
    "print_json(category_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e86ab01-302b-4d5c-9efa-3a97b8eb15f0",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "\n",
    "Imports and explores basic aspects of FER 2013 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdccf2a-87d3-48a6-b5a3-e0d8f2004898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in FER 2013 data\n",
    "fer2013_path = 'data/fer2013.csv'\n",
    "fer2013 = pd.read_csv(fer2013_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc945b3-3805-4d29-9e32-bcf0e11c4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names and shape\n",
    "print(fer2013.columns)\n",
    "print(fer2013.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41010d-69d6-44f7-80b1-702de5a885fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check emotion values\n",
    "print(sorted(fer2013['emotion'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df27738d-078d-46b0-b601-76e759c7131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map emotion labels to values for clarity\n",
    "fer2013 = fer2013.rename(columns={'emotion': 'emotion_id'})\n",
    "fer2013['emotion'] = fer2013['emotion_id'].astype(str).map(emo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710c0ac-9bd8-409f-b4d2-9ce5dc0940f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel data converted to np.array\n",
    "fer2013['image'] = fer2013['pixels'].apply(convert_pixels_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc4b6d-929b-44ec-90bc-69eca16f77aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data has 3 usages: train, public test, private test\n",
    "# Mapping reduces to train and test only \n",
    "fer2013['usage']=fer2013['Usage'].map(common_dicts['usage_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a64a9b-46b6-4a53-afab-6f29ce1c7b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add emotion color tags\n",
    "fer2013['color'] = fer2013['emotion'].map(emo_color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58a8eb-ce5e-4c47-9d9e-177d8d8c37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create counts of each emotion\n",
    "gby = fer2013.groupby(['emotion'], as_index=False, observed=True).size()\n",
    "gby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f3ef3-8e0b-4ae3-ad9f-9c3b506c6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a color column to the DataFrame based on the emotion\n",
    "gby['color'] = gby['emotion'].map(emo_color_dict)\n",
    "gby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25718a8-b7d6-4688-8b52-5798c52ed318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the order list to include only categories present in the DataFrame\n",
    "filtered_order = [cat for cat in category_order if cat in gby['emotion'].unique()]\n",
    "print(filtered_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b18275-485a-4168-adbf-a30e4b6746ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert emotion column data type to be categorical for plotting\n",
    "gby['emotion'] = pd.Categorical(gby['emotion'], categories=filtered_order, ordered=True)\n",
    "gby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8757bd-05fa-44f9-99eb-cbf306c40045",
   "metadata": {},
   "source": [
    "### Count Plot\n",
    "\n",
    "Using count data, generates a barplot to visual category distribution.\n",
    "\n",
    "More advanced plots are generated in next notebook.\n",
    "\n",
    "FutureWarnings arise during this step and are ignored as they do not impact the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3276cc-b5cd-4b55-af67-19b4ce16b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(data=gby, x='emotion', y='size', ax=ax, palette=gby['color'])\n",
    "    \n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Emotion Image Counts')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3190c336-c9d8-420b-8702-803e411e978d",
   "metadata": {},
   "source": [
    "### Save Data\n",
    "\n",
    "Each image is saved to a jpg based on usage (train/test) and emotion category.\n",
    "\n",
    "An identifying interger is added to filenames, for organization.\n",
    "\n",
    "A new csv, fer2013_paths.csv, is written out to the data directory with filepaths for all generated images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa192009-b593-4b02-9ef6-63edda8c00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a numeric index for each usage/emotion group\n",
    "fer2013['emo_count_id'] = fer2013.groupby(['usage', 'emotion']).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8d172-35f2-4673-a7a4-41bf38403d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write image to jpg and returns filepath\n",
    "fer2013['img_path'] = fer2013.apply(save_image, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d347c-8737-48c2-a6d7-ed9f469a5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated df\n",
    "save_path = os.path.join('data', 'fer2013_paths.csv')\n",
    "fer2013.to_csv(save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
