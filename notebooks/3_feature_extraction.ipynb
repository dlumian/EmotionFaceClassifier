{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f3a450-d3f4-4e18-9a97-93f4b4d892be",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "## Emotion Face Classifier Notebook 3\n",
    "\n",
    "Uses unsupervised decomposition models to extract averaged features of images by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c5ba44f-8d05-4bc3-bc37-8342bf24f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7004192-0562-4786-898e-a5a6ee97776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef616a3f-417d-4c75-b402-70855ccee1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe936733-29e0-4b2a-918b-ecc2aaed23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d2509a7-8d5d-4e83-beec-8f865dc66399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascifuncs.tidbit_tools import load_json, write_json, print_json, check_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c2ce467-6979-4a59-bc52-da13108c04ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory set to /Users/dsl/Documents/GitHub/EmotionFaceClassifier, matches target dir string EmotionFaceClassifier.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dir = 'EmotionFaceClassifier'\n",
    "check_directory_name(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ac803d0-d11d-4b75-86f5-8080c99f34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.feature_extraction import perform_unsupervised_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f7e2a7b-f031-4568-96f9-88ee82db26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dicts = load_json('./configs/input_mappings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9514b553-0de4-43c1-928f-0e74d12e0e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_colors = common_dicts['plotly_styles']['Training']['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b85847b-b60a-4250-92fa-9447b7b71d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in FER 2013 data\n",
    "fer2013_path = 'data/fer2013_paths.csv'\n",
    "fer2013 = pd.read_csv(fer2013_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a9cd4ff-8e2c-4bf2-9d23-66848d216000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "      <th>emotion</th>\n",
       "      <th>image</th>\n",
       "      <th>usage</th>\n",
       "      <th>emo_count_id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Angry</td>\n",
       "      <td>[[ 70  80  82 ...  52  43  41]\\n [ 65  61  58 ...</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>data/Training/Angry/Angry-1.jpg</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Angry</td>\n",
       "      <td>[[151 150 147 ... 129 140 120]\\n [151 149 149 ...</td>\n",
       "      <td>Training</td>\n",
       "      <td>2</td>\n",
       "      <td>data/Training/Angry/Angry-2.jpg</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Fear</td>\n",
       "      <td>[[231 212 156 ...  44  27  16]\\n [229 175 148 ...</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>data/Training/Fear/Fear-1.jpg</td>\n",
       "      <td>slategray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[[ 24  32  36 ... 173 172 173]\\n [ 25  34  29 ...</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>data/Training/Sad/Sad-1.jpg</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[[ 4  0  0 ... 27 24 25]\\n [ 1  0  0 ... 26 23...</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>data/Training/Neutral/Neutral-1.jpg</td>\n",
       "      <td>sienna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion_id                                             pixels     Usage  \\\n",
       "0           0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training   \n",
       "1           0  151 150 147 155 148 133 111 140 170 174 182 15...  Training   \n",
       "2           2  231 212 156 164 174 138 161 173 182 200 106 38...  Training   \n",
       "3           4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training   \n",
       "4           6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training   \n",
       "\n",
       "   emotion                                              image     usage  \\\n",
       "0    Angry  [[ 70  80  82 ...  52  43  41]\\n [ 65  61  58 ...  Training   \n",
       "1    Angry  [[151 150 147 ... 129 140 120]\\n [151 149 149 ...  Training   \n",
       "2     Fear  [[231 212 156 ...  44  27  16]\\n [229 175 148 ...  Training   \n",
       "3      Sad  [[ 24  32  36 ... 173 172 173]\\n [ 25  34  29 ...  Training   \n",
       "4  Neutral  [[ 4  0  0 ... 27 24 25]\\n [ 1  0  0 ... 26 23...  Training   \n",
       "\n",
       "   emo_count_id                             img_path      color  \n",
       "0             1      data/Training/Angry/Angry-1.jpg        red  \n",
       "1             2      data/Training/Angry/Angry-2.jpg        red  \n",
       "2             1        data/Training/Fear/Fear-1.jpg  slategray  \n",
       "3             1          data/Training/Sad/Sad-1.jpg       blue  \n",
       "4             1  data/Training/Neutral/Neutral-1.jpg     sienna  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fer2013.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48450ff3-1948-4152-8415-c8bb0efb6b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35887, 9)\n",
      "(28709, 9)\n"
     ]
    }
   ],
   "source": [
    "# Select training data\n",
    "print(fer2013.shape)\n",
    "train_df = fer2013[fer2013['usage']=='Training']\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70f828fc-fa5c-477c-8d8d-2ca6e74a0992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.feature_extraction import perform_unsupervised_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0155aa6a-cf84-43fc-8ce6-e047684d48fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (28709, 2304), y shape: (28709,)\n",
      "Total number of analyses to be run: 3\n",
      "\n",
      "Starting analysis 1/3\n",
      "Analysis type: NMF\n",
      "Normalization: none\n",
      "Total components: 50\n",
      "Parameters: {'init': 'random', 'solver': 'mu', 'beta_loss': 'frobenius', 'max_iter': 1000, 'tol': 1e-05, 'random_state': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2304 is different from 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m perform_unsupervised_analysis(\n\u001b[1;32m      2\u001b[0m     df\u001b[38;5;241m=\u001b[39mtrain_df,\n\u001b[1;32m      3\u001b[0m     img_path_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_path\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     label_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     config_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfigs/unsupervised_models.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     analysis_types\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNMF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFastICA\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# analysis_types=['PCA', 'NMF', 'FastICA'],\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     emotion_colors\u001b[38;5;241m=\u001b[39memotion_colors,\n\u001b[1;32m      9\u001b[0m     flatten\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     img_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/EmotionFaceClassifier/utils/feature_extraction.py:410\u001b[0m, in \u001b[0;36mperform_unsupervised_analysis\u001b[0;34m(df, img_path_column, label_column, config_path, analysis_types, emotion_colors, flatten, img_size)\u001b[0m\n\u001b[1;32m    407\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(result_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# Run the analysis\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m results, metrics_df \u001b[38;5;241m=\u001b[39m run_analysis(X, y, analysis_type, normalizer, analyses_config, config)\n\u001b[1;32m    412\u001b[0m             \u001b[38;5;66;03m# Check component uniqueness\u001b[39;00m\n\u001b[1;32m    413\u001b[0m check_component_uniqueness(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/GitHub/EmotionFaceClassifier/utils/feature_extraction.py:258\u001b[0m, in \u001b[0;36mrun_analysis\u001b[0;34m(X, y, analysis_type, normalizer, analyses_config, config)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# if analysis_type == 'NMF':\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m#     model = NMF(n_components=n_components, **params)\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# elif analysis_type == 'PCA':\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m \n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Perform fit_transform for all X\u001b[39;00m\n\u001b[1;32m    257\u001b[0m features_all \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit_transform(X_normalized)\n\u001b[0;32m--> 258\u001b[0m reconstructions_all, metrics_all \u001b[38;5;241m=\u001b[39m partial_reconstruction(model, features_all, component_values, X_normalized)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# Initialize results\u001b[39;00m\n\u001b[1;32m    261\u001b[0m avg_categories \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mmean(reconstruction, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m reconstruction \u001b[38;5;129;01min\u001b[39;00m reconstructions_all]\n",
      "File \u001b[0;32m~/Documents/GitHub/EmotionFaceClassifier/utils/feature_extraction.py:126\u001b[0m, in \u001b[0;36mpartial_reconstruction\u001b[0;34m(model, features, component_values, original_data)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_components \u001b[38;5;129;01min\u001b[39;00m component_values:\n\u001b[1;32m    125\u001b[0m     partial_features \u001b[38;5;241m=\u001b[39m features[:, :n_components]\n\u001b[0;32m--> 126\u001b[0m     reconstruction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minverse_transform(partial_features)\n\u001b[1;32m    127\u001b[0m     reconstructions\u001b[38;5;241m.\u001b[39mappend(reconstruction)\n\u001b[1;32m    128\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mappend(calculate_metrics(original_data, reconstruction, n_components))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py:1258\u001b[0m, in \u001b[0;36m_BaseNMF.inverse_transform\u001b[0;34m(self, W)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform data back to its original space.\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \n\u001b[1;32m   1245\u001b[0m \u001b[38;5;124;03m.. versionadded:: 0.18\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;124;03m    Returns a data matrix of the original shape.\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m W \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2304 is different from 1)"
     ]
    }
   ],
   "source": [
    "perform_unsupervised_analysis(\n",
    "    df=train_df,\n",
    "    img_path_column='img_path',\n",
    "    label_column='emotion',\n",
    "    config_path='configs/unsupervised_models.json',\n",
    "    analysis_types=['NMF', 'FastICA'],\n",
    "    # analysis_types=['PCA', 'NMF', 'FastICA'],\n",
    "    emotion_colors=emotion_colors,\n",
    "    flatten=True,\n",
    "    img_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0698ec1-b3c2-4109-8053-d9c57ed88ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
