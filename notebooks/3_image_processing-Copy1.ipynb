{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff98d76-19b6-4f68-96b5-df5c6ac04b0f",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) Image Analysis \n",
    "\n",
    "## Emotion Face Classifier Notebook 3\n",
    "\n",
    "Visuals example images, image properties, and uses unsupervised models for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32a016-6c5b-4966-97da-b65e4b782f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d6bcc-d1e5-47d4-9ab6-5079f6204c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7121b1e-a55e-411b-a994-e2a9d5796d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f1e003-42de-4416-8997-91dec6e09e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datascifuncs.tidbit_tools import load_json, write_json, print_json, check_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890eb401-b50a-448f-a82c-b146347ff804",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = 'EmotionFaceClassifier'\n",
    "check_directory_name(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea49cf9a-6044-4e07-a9ea-0df70071e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.image_processing import (\n",
    "    generate_sample_images,\n",
    "    plot_matrix,\n",
    "    preprocess_images,\n",
    "    apply_ticks,\n",
    "    set_spines_and_titles_by_column,\n",
    "    add_figure_title,\n",
    "    add_text_box,\n",
    "    save_figure\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df949981-42b3-4935-9075-d1006e951b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.image_processing import (\n",
    "#     preprocess_images,\n",
    "#     generate_sample_images,\n",
    "#     plot_face_matrix,\n",
    "#     generate_composite_faces,\n",
    "#     run_dimensionality_reduction,\n",
    "#     generate_pixel_intensities\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a9fb39-75e3-4c50-bdf8-be99caa8935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.analysis_tools import instantiate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c350f91-dd7c-4edf-8986-16d59ac5ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in FER 2013 data\n",
    "fer2013_path = 'data/fer2013_paths.csv'\n",
    "fer2013 = pd.read_csv(fer2013_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994a69fa-c0f5-487a-9fda-0c4c1246515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fer2013.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a7923-748b-4868-bdff-a351b956bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select training data\n",
    "print(fer2013.shape)\n",
    "train_df = fer2013[fer2013['usage']=='Training']\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fea1d3-66c5-4622-804b-5aabc81c9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load common dicts from json config file\n",
    "common_dicts = load_json('./configs/input_mappings.json')\n",
    "# print_json(common_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237d8e4b-1e99-441e-b9ee-ee47f4c4159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subset of emo-color mappings\n",
    "color_dict = common_dicts['plotly_styles']['Training']['color']\n",
    "color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f21385-c5dd-4ce5-b820-545141e35985",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_samples = generate_sample_images(train_df, n=5, cat_col='emotion', path_col='img_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c563c34-82ff-4985-ae99-80b8f97edefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d338f-d9f5-4b9a-a326-2e4184016815",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = load_json('./configs/plotting_params.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684598aa-2274-42e0-ad2e-da07a94109be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_imgs_save_path = os.path.join('imgs', 'comparisons', 'sample_images.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbce2ce-8b3f-412d-8740-3d21036d8f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_matrix(\n",
    "    image_dict=emo_samples, \n",
    "    row_labels=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519be44e-6b19-4142-a054-077924f993c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_ticks(axes, plot_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430e5d1-7481-4a14-b7dc-975c9f872d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2623e8d4-987f-4785-a0a8-2c2acfa45346",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_spines_and_titles_by_column(axes, title_colors=color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f123944-2c7e-409c-ab1d-08944350f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17158a21-850a-47b9-a8fa-488d0052af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_figure_title(fig, plot_params['figure_title'], 'Example Faces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d522a3dc-bcc6-4abf-a7ad-695352cbe79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4c466-773c-4906-8562-843231b2d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_text_box(fig, plot_params['text_box'], text='Example 48x48 grayscale images from each category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabcae61-dffb-40a6-ac35-070b92f2b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f566a93-9922-4b07-869a-325f6c6c724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('imgs', 'comparisons', 'sample_images.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468d24d-35ad-4f84-8c42-1f8f5130079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figure(fig, save_path=save_path, dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e1a37-c7d5-4fca-9b25-cd71a85ab956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = preprocess_images(fer2013, usage='Training', flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e5371-d666-49e7-ab22-57cd45402b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel_imgs_save_path = os.path.join('imgs', 'comparisons', 'pixel_intensities.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e5a3d-a92c-4836-8d6b-f2fd351c85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_pixel_intensities(X_train, y_train, color_dict=color_dict, save_path=pixel_imgs_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64966198-1fc4-496b-9352-6869c1acf0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# composite_face_dict, row_labels = generate_composite_faces(X_train, y_train, overall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a99e75-8c29-43ae-a751-52ee8d860e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# composite_imgs_save_path = os.path.join('imgs', 'comparisons', 'composite_faces.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2379c977-a297-4925-949c-2ec04ab570e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_matrix(\n",
    "#     image_dict=composite_face_dict, \n",
    "#     row_labels=row_labels\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
