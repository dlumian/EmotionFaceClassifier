{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d79a7bb-5644-41b9-a229-14c2c71e3a7a",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) Image Analysis \n",
    "\n",
    "## Emotion Face Classifier Notebook 3\n",
    "\n",
    "Focuses on showing example expressions and aggregrate representations of emotion categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c2476-6427-423d-b9e6-6ea3c6b5bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2507bb-bfe5-4fdc-9113-fad539332c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datascifuncs.tidbit_tools import load_json, write_json, print_json, check_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7640a-9f6a-49b2-b946-58cc48ea1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = 'EmotionFaceClassifier'\n",
    "check_directory_name(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0536c512-fc78-4cd3-ad32-467ca0d67ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.image_processing import (\n",
    "    display_random_images_from_df,\n",
    "    preprocess_image,\n",
    "    apply_pca,\n",
    "    compute_average_face,\n",
    "    log_pca_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47971749-14c1-4d41-981c-9e59fdd900c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in FER 2013 data\n",
    "fer2013_path = 'data/fer2013_paths.csv'\n",
    "fer2013 = pd.read_csv(fer2013_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae703f6-33ad-45ba-9aba-357dc0512fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fer2013.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da448ad6-081f-4415-ab63-f5a03ac365f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load common dicts from json config file\n",
    "common_dicts = load_json('./configs/input_mappings.json')\n",
    "print_json(common_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f198885-8789-491d-86e5-24c3a98b3190",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = common_dicts['plotly_styles']['Training']['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41252d-35f3-4809-9cf1-0723ab4ef339",
   "metadata": {},
   "source": [
    "## Display Example Images from Each Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c0a8d-0dac-4827-b8bd-ef4dc25f539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_images_from_df(fer2013, n_rows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d0f811-d204-4893-ad6c-9a9a6bb63e82",
   "metadata": {},
   "source": [
    "## Unsupervised Learning Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8692a59a-b759-48d3-9eb6-7fb79d4a416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: datasets/emotions/happy, datasets/emotions/sad, etc.\n",
    "emotions = fer2013['emotion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e024f-ba22-4815-b1c6-b6bdd7f0ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold images by category\n",
    "images_by_category = {emotion: [] for emotion in emotions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a430e-29f4-4cc2-b48b-3f563f7efe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group images by emotion\n",
    "emotion_groups = fer2013.groupby('emotion')\n",
    "\n",
    "# Iterate over each emotion category efficiently\n",
    "for emotion, group in emotion_groups:\n",
    "    # Preprocess each image using a list comprehension\n",
    "    images = [preprocess_image(cv2.imread(img_path)) for img_path in group['img_path']]\n",
    "    \n",
    "    # Store preprocessed images for this emotion\n",
    "    images_by_category[emotion] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc87bff0-0022-43e3-9c83-78acd6fea9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA and compute the average face for each category\n",
    "n_components = 50\n",
    "for emotion, images in images_by_category.items():\n",
    "    print(f\"Processing category: {emotion}\")\n",
    "    \n",
    "    # Apply PCA\n",
    "    transformed_images, pca = apply_pca(images, n_components)\n",
    "    \n",
    "    # Compute the average face\n",
    "    average_face = compute_average_face(images)\n",
    "    \n",
    "    # Log the PCA and average face results with MLflow\n",
    "    log_pca_results(pca, average_face, emotion)\n",
    "    \n",
    "    # Display the average face\n",
    "    plt.imshow(average_face, cmap='gray')\n",
    "    plt.title(f\"Average Face: {emotion}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81788c2-6576-4034-a0d1-1c343e2379bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab845d8-ae8c-4b33-a607-2c69140701ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704c674-01d7-4160-a7a4-104a93524e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332a4d5-e673-4e1e-9d8e-eb25cd6d7d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ed75f-d4c1-47a0-918c-01524a9ef64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e186aba-743c-483a-adf8-ca462325f22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad95c8c-4978-474b-85a5-2a94877a1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# # Define emotion-to-color mapping\n",
    "# emotion_colors = {\n",
    "#     'happy': 'yellow',\n",
    "#     'sad': 'blue',\n",
    "#     'angry': 'red',\n",
    "#     'surprised': 'green'\n",
    "# }\n",
    "\n",
    "# Directories where images and PCA arrays are stored\n",
    "average_face_dir = 'imgs/facial_features'\n",
    "pca_array_dir = 'data/pca_arrays'\n",
    "\n",
    "# Emotions you're working with\n",
    "emotions = common_dicts['emo_dict'].values()\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(2, len(emotions), figsize=(15, 10))  # 2 rows for PCA and average faces\n",
    "\n",
    "# Iterate over emotions and create subplots for PCA and average faces\n",
    "for idx, emotion in enumerate(emotions):\n",
    "    \n",
    "    # Load the average face image\n",
    "    avg_face_path = os.path.join(average_face_dir, f\"average_face_{emotion}.png\")\n",
    "    avg_face_img = cv2.imread(avg_face_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Load the PCA components or a reconstructed image from PCA if you have one\n",
    "    pca_components_path = os.path.join(pca_array_dir, f\"pca_components_{emotion}.npy\")\n",
    "    pca_components = np.load(pca_components_path)  # Loaded PCA array (adjust how you visualize this)\n",
    "    \n",
    "    # ------------------------ Plotting Average Face ------------------------\n",
    "    ax_avg = axes[0, idx]\n",
    "    ax_avg.imshow(avg_face_img, cmap='gray')\n",
    "    ax_avg.set_title(f'Average Face: {emotion}')\n",
    "    ax_avg.axis('off')  # Hide axis for clean display\n",
    "    \n",
    "    # Add a colored border frame around the average face plot\n",
    "    rect_avg = Rectangle((0, 0), 1, 1, transform=ax_avg.transAxes,\n",
    "                         linewidth=5, edgecolor=color_dict[emotion], facecolor='none')\n",
    "    ax_avg.add_patch(rect_avg)\n",
    "\n",
    "    # ------------------------ Plotting PCA Image ------------------------\n",
    "    ax_pca = axes[1, idx]\n",
    "    \n",
    "    # Assuming you have a way to visualize PCA components or a reconstructed face\n",
    "    # For illustration, let's plot the first principal component reshaped to image size\n",
    "    pca_img = pca_components[0].reshape(avg_face_img.shape)  # Reshape based on your image dimensions\n",
    "    ax_pca.imshow(pca_img, cmap='gray')\n",
    "    ax_pca.set_title(f'PCA Face: {emotion}')\n",
    "    ax_pca.axis('off')\n",
    "\n",
    "    # Add a colored border frame around the PCA face plot\n",
    "    rect_pca = Rectangle((0, 0), 1, 1, transform=ax_pca.transAxes,\n",
    "                         linewidth=5, edgecolor=color_dict[emotion], facecolor='none')\n",
    "    ax_pca.add_patch(rect_pca)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c815ff-d0e0-4dc9-840d-4689a595a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an additional subplot to combine all average faces\n",
    "ax_all = fig.add_subplot(2, len(emotions) + 1, len(emotions) * 2)  # One extra column for comparison\n",
    "\n",
    "# Combine all average faces into one composite image\n",
    "all_avg_faces = np.mean([cv2.imread(os.path.join(average_face_dir, f\"average_face_{emotion}.png\"),\n",
    "                                    cv2.IMREAD_GRAYSCALE) for emotion in emotions], axis=0)\n",
    "ax_all.imshow(all_avg_faces, cmap='gray')\n",
    "ax_all.set_title('All Average Faces')\n",
    "ax_all.axis('off')\n",
    "\n",
    "# You can similarly do this for PCA faces if needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604aee6e-e6b2-4d2c-abaf-c3ecbbc8bf58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763376b-eb42-4ad8-8676-2004038c13ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
