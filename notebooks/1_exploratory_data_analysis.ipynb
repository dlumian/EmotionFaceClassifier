{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e77f146-b900-4430-898c-f1b50a9aa0ac",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Emotion Face Classifier Notebook 1\n",
    "\n",
    "Data load and harmonization\n",
    "\n",
    "Summaries and visualizations include:\n",
    "- Skimpy reports\n",
    "- Barplot of image count by emotion\n",
    "- Waffle chart of image distribution\n",
    "- Displaying example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cba53c-cb2e-4c95-99ef-442f4f760639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from skimpy import skim_get_figure\n",
    "from datascifuncs.tidbit_tools import load_json, write_json, check_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71acb85a-ef3a-4ff6-b822-454ebc8ca161",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = 'EmotionFaceClassifier'\n",
    "check_directory_name(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e68725-3525-44a3-9dd5-86268cd3cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_ingest_eda import (\n",
    "    generate_file_dataframe,\n",
    "    emotion_count_piv,\n",
    "    piv_stacked_bar,\n",
    "    waffle_chart,\n",
    "    show_example_images,\n",
    "    convert_pixels_to_array,\n",
    "    create_img\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48838e1f-7801-461e-9f1c-5d8074ac5f47",
   "metadata": {},
   "source": [
    "## FER2013 Data Harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d728cf60-7774-4347-954e-c6e7089e1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('imgs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4edfba8-4c4b-4ac3-b974-456153519d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load common dicts from json config file\n",
    "common_dicts = load_config('./configs/input_mappings.json')\n",
    "print(common_dicts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe895c00-6ca0-456b-be24-959e33b7c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in key dicts from json for data mapping\n",
    "emo_dict = common_dicts['emo_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07068e0e-6d7f-48e3-b4aa-3cc51dd3236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in key dicts from json for data mapping\n",
    "emo_color_dict = common_dicts['emo_color_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8cb1fb-5198-43e4-815e-c803c73376f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "fer2013_path = 'data/fer2013/fer2013.csv'\n",
    "fer2013 = pd.read_csv(fer2013_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf7b142-efe4-446f-91f5-447d9ad3be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify df for clarity\n",
    "fer2013 = fer2013.rename(columns={'emotion': 'emotion_id'})\n",
    "fer2013['emotion'] = fer2013['emotion_id'].astype(str).map(emo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da25858e-fed8-43fb-a6d9-0924c2b0fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel data must be converted to np.array\n",
    "fer2013['image'] = fer2013['pixels'].apply(convert_pixels_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19408d93-8bcd-473f-bc66-40b68e095da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data has 3 usages: train, public test, private test\n",
    "# Mapping reduces to train and test only \n",
    "fer2013['usage']=fer2013['Usage'].map(common_dicts['usage_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d9eaa-5761-4368-9788-bca43f0040fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a numeric index for each usage/emotion group\n",
    "# Value does not hold meaning expect as identifier for image\n",
    "fer2013['emo_count_id'] = fer2013.groupby(['usage', 'emotion']).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4024e-8fd1-4971-9f9a-45f65a92623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in fer2013.iterrows():\n",
    "    create_img(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e529d3-aa77-4386-bebf-08f2c73055dd",
   "metadata": {},
   "source": [
    "## Data Summary and Pivots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94afdb5a-df39-4f53-a064-78d233e2bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fer = generate_file_dataframe('data/fer2013/')\n",
    "fer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1feb1f8-4240-40aa-b731-95ccce8cd445",
   "metadata": {},
   "outputs": [],
   "source": [
    "frd = generate_file_dataframe('data/frd2020/')\n",
    "frd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd604f28-9e94-42fc-a76e-a7f59a2ee8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set source column\n",
    "fer['source'] = 'fer'\n",
    "frd['source'] = 'frd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f05caf-78f2-4353-a188-7b467961da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([fer, frd], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fabf33-6f2e-40ff-99a0-45200427980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save combined data\n",
    "# combined_df_path = os.path.join('data', 'efc2024.csv')\n",
    "# df.to_csv(combined_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f80503-9982-4738-b140-a579c6f14d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fer.shape)\n",
    "print(frd.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f55ae-c309-42c7-94e5-30ee8bf42f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a62e64-0948-44d1-83fc-0faa24bcb4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify df for clarity\n",
    "# df = df.rename(columns={'emotion': 'emotion_id'})\n",
    "# df['emotion'] = df['emotion_id'].astype(str).map(emo_dict)\n",
    "fer['color'] = fer['emotion'].map(emo_color_dict)\n",
    "frd['color'] = frd['emotion'].map(emo_color_dict)\n",
    "df['color'] = df['emotion'].map(emo_color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12fdc31-925b-4e59-956c-31f37d0c6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76552dab-f9ad-49c9-ad53-445531ed6064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\n",
    "    'fer2013': fer,\n",
    "    'frd2020': frd,\n",
    "    'efc2024': df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1655d68-ef89-459b-92d5-fc937e146b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skim will generate and save a file with basic descriptives\n",
    "for df_str, pd_df in df_dict.items():\n",
    "    out_path = os.path.join('imgs', f'{df_str}_skim.svg')\n",
    "    skim_get_figure(pd_df, save_path=out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bab44be-3af9-4d17-ab03-0a165b979187",
   "metadata": {},
   "source": [
    "## Pivots grouped by Emotion and Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118b5e8-3612-4c26-b81a-96ded53f4d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skim will generate and save a file with basic descriptives\n",
    "for df_str, pd_df in df_dict.items():\n",
    "    piv_df = emotion_count_piv(\n",
    "        df=pd_df,\n",
    "        gby_cols=['emotion', 'train_test_split'], \n",
    "        agg_col='Filename',\n",
    "        count_cols=['Training', 'Testing']\n",
    "    )\n",
    "\n",
    "    # Skim package for a nice overview, saved to save_path below\n",
    "    out_path = os.path.join('imgs', f'{df_str}_counts_skim.svg')\n",
    "    skim_get_figure(piv_df, save_path=out_path)\n",
    "\n",
    "    # Bar plot of emotion image counts\n",
    "    piv_stacked_bar(df=piv_df, label=df_str)\n",
    "\n",
    "    # Waffle plot of distribution\n",
    "    waffle_path = os.path.join('imgs', f'{df_str}_waffle_chart.png')\n",
    "    waffle_chart(\n",
    "        df=piv_df, group_col='Emotion', data_col='TotalImages', \n",
    "        save_path=waffle_path, display=False, total_squares=100,\n",
    "        color_dict=emo_color_dict\n",
    "    )\n",
    "\n",
    "    # Save pivoted data\n",
    "    intermediate_data_dir = os.path.join('data', 'intermediate_data')\n",
    "    os.makedirs(intermediate_data_dir, exist_ok=True)\n",
    "    piv_save_path = os.path.join(intermediate_data_dir, f'{df_str}_emo_piv.csv')\n",
    "    piv_df.to_csv(piv_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0075ab-5048-49b9-abb1-69a52581468e",
   "metadata": {},
   "source": [
    "## Example Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb0aa6-09af-4e0a-b49f-14fd98fdb72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images=False\n",
    "for df_str, pd_df in df_dict.items():\n",
    "    # Creates image with 1 example face/emotion\n",
    "    fig, axes = show_example_images(\n",
    "        df=pd_df, group_col='emotion', image_col='Full Path', \n",
    "        save_path=f'./imgs/{df_str}_examples_1.png', samples=1,\n",
    "        display=display_images)\n",
    "\n",
    "    # Creates image with 3 example face/emotion\n",
    "    fig, axes = show_example_images(\n",
    "        df=pd_df, group_col='emotion', image_col='Full Path', \n",
    "        save_path=f'./imgs/{df_str}_examples_3.png', samples=3,\n",
    "        display=display_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013711d-d8a2-4b04-8c49-202ae08fe470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
