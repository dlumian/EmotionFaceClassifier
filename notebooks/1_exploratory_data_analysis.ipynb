{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e77f146-b900-4430-898c-f1b50a9aa0ac",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Emotion Face Classifier Notebook 1\n",
    "\n",
    "Data load and harmonization\n",
    "\n",
    "Summary pivot counts of emotion by data source and combined\n",
    "\n",
    "Visualizations:\n",
    "- Skimpy reports\n",
    "- Barplot of image count by emotion\n",
    "- Waffle chart of image distribution\n",
    "- Example image displays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37745572-4b0b-429b-a7fa-3cdbe83feb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cba53c-cb2e-4c95-99ef-442f4f760639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from skimpy import skim_get_figure\n",
    "from datascifuncs.tidbit_tools import load_json, write_json, print_json, check_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71acb85a-ef3a-4ff6-b822-454ebc8ca161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory set to /Users/dsl/Documents/GitHub/EmotionFaceClassifier, matches target dir string EmotionFaceClassifier.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dir = 'EmotionFaceClassifier'\n",
    "check_directory_name(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5308118f-19ee-4deb-814c-f019d3d67811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eda import (\n",
    "    convert_pixels_to_array,\n",
    "    save_image\n",
    ")\n",
    "\n",
    "from utils.image_processing import create_image_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48838e1f-7801-461e-9f1c-5d8074ac5f47",
   "metadata": {},
   "source": [
    "## FER2013 Data Harmonization\n",
    "\n",
    "Image data is contained in a csv file as a flattened string.\n",
    "\n",
    "To sync with FRD 2020 data, arrays are extracted, converted into 2-D, and written to greyscale jpg images.\n",
    "\n",
    "Directory structure matches that of FRD with usage (train or test) followed by emotion type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d728cf60-7774-4347-954e-c6e7089e1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('imgs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4edfba8-4c4b-4ac3-b974-456153519d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"usage_dict\": {\n",
      "        \"Training\": \"Training\",\n",
      "        \"PublicTest\": \"Testing\",\n",
      "        \"PrivateTest\": \"Testing\"\n",
      "    },\n",
      "    \"emo_dict\": {\n",
      "        \"0\": \"Angry\",\n",
      "        \"1\": \"Disgust\",\n",
      "        \"2\": \"Fear\",\n",
      "        \"3\": \"Happy\",\n",
      "        \"4\": \"Sad\",\n",
      "        \"5\": \"Surprise\",\n",
      "        \"6\": \"Neutral\"\n",
      "    },\n",
      "    \"frd_emo_dict\": {\n",
      "        \"0\": \"Angry\",\n",
      "        \"1\": \"Fear\",\n",
      "        \"2\": \"Happy\",\n",
      "        \"3\": \"Sad\",\n",
      "        \"4\": \"Surprise\",\n",
      "        \"5\": \"Neutral\"\n",
      "    },\n",
      "    \"emo_color_dict\": {\n",
      "        \"Angry\": \"red\",\n",
      "        \"Disgust\": \"olive\",\n",
      "        \"Fear\": \"black\",\n",
      "        \"Happy\": \"gold\",\n",
      "        \"Sad\": \"blue\",\n",
      "        \"Surprise\": \"darkviolet\",\n",
      "        \"Neutral\": \"slategray\"\n",
      "    },\n",
      "    \"output_col_order\": [\n",
      "        \"Emotion\",\n",
      "        \"TotalImages\",\n",
      "        \"Training\",\n",
      "        \"TrainingPerc\",\n",
      "        \"PublicTest\",\n",
      "        \"PublicTestPerc\",\n",
      "        \"PrivateTest\",\n",
      "        \"PrivateTestPerc\"\n",
      "    ],\n",
      "    \"frd_output_col_order\": [\n",
      "        \"Emotion\",\n",
      "        \"TotalImages\",\n",
      "        \"Training\",\n",
      "        \"TrainingPerc\",\n",
      "        \"Testing\",\n",
      "        \"TestingPerc\"\n",
      "    ],\n",
      "    \"img_directories\": {\n",
      "        \"fer2013\": \"data/fer2013\",\n",
      "        \"frd2020\": \"data/frd2020\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load common dicts from json config file\n",
    "common_dicts = load_json('./configs/input_mappings.json')\n",
    "print_json(common_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe895c00-6ca0-456b-be24-959e33b7c885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"0\": \"Angry\",\n",
      "    \"1\": \"Disgust\",\n",
      "    \"2\": \"Fear\",\n",
      "    \"3\": \"Happy\",\n",
      "    \"4\": \"Sad\",\n",
      "    \"5\": \"Surprise\",\n",
      "    \"6\": \"Neutral\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Select emotion mapping section of json\n",
    "emo_dict = common_dicts['emo_dict']\n",
    "print_json(emo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07068e0e-6d7f-48e3-b4aa-3cc51dd3236a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Angry\": \"red\",\n",
      "    \"Disgust\": \"olive\",\n",
      "    \"Fear\": \"black\",\n",
      "    \"Happy\": \"gold\",\n",
      "    \"Sad\": \"blue\",\n",
      "    \"Surprise\": \"darkviolet\",\n",
      "    \"Neutral\": \"slategray\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Select color mappings for emotion categories\n",
    "emo_color_dict = common_dicts['emo_color_dict']\n",
    "print_json(emo_color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c8cb1fb-5198-43e4-815e-c803c73376f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in FER 2013 data\n",
    "fer2013_path = 'data/fer2013/fer2013.csv'\n",
    "fer2013 = pd.read_csv(fer2013_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9094b19-2d6a-409c-b2e6-bb9e78b78902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['emotion', 'pixels', 'Usage'], dtype='object')\n",
      "(35887, 3)\n"
     ]
    }
   ],
   "source": [
    "# Check column names and shape\n",
    "print(fer2013.columns)\n",
    "print(fer2013.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21b6db85-392e-49d9-a34b-af184edc23ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "# Check emotion values\n",
    "print(sorted(fer2013['emotion'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cf7b142-efe4-446f-91f5-447d9ad3be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map emotion labels to values for clarity and harmonization\n",
    "fer2013 = fer2013.rename(columns={'emotion': 'emotion_id'})\n",
    "fer2013['emotion'] = fer2013['emotion_id'].astype(str).map(emo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da25858e-fed8-43fb-a6d9-0924c2b0fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel data must be converted to np.array\n",
    "fer2013['image'] = fer2013['pixels'].apply(convert_pixels_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19408d93-8bcd-473f-bc66-40b68e095da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data has 3 usages: train, public test, private test\n",
    "# Mapping reduces to train and test only \n",
    "fer2013['usage']=fer2013['Usage'].map(common_dicts['usage_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b6d9eaa-5761-4368-9788-bca43f0040fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a numeric index for each usage/emotion group\n",
    "# Value is used as identifier for image\n",
    "fer2013['emo_count_id'] = fer2013.groupby(['usage', 'emotion']).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25a3a598-1ead-4ea2-acad-7c2a43ccd5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "35882    None\n",
       "35883    None\n",
       "35884    None\n",
       "35885    None\n",
       "35886    None\n",
       "Length: 35887, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write img arrays to jpg for data harmony\n",
    "fer2013.apply(save_image, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e529d3-aa77-4386-bebf-08f2c73055dd",
   "metadata": {},
   "source": [
    "## Data Summary and Pivots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce4f3a19-34fc-4324-b2b7-97b694a4cf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path where your datasets are located\n",
    "base_path = 'data'\n",
    "datasets = ['fer2013', 'frd2020']\n",
    "usages = ['Training', 'Testing']\n",
    "emotions = common_dicts['frd_emo_dict'].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc4918-f8d0-412c-b52c-13454faad1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_structure = {\n",
    "    'dataset': datasets,\n",
    "    'usage': usages,\n",
    "    'emotion': emotions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6daf3-fb63-4478-b843-6a5e797183e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_image_dataframe(base_path=base_path, search_structure=search_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a450c717-02d1-4963-833d-42b203cfd36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "687f6afb-732f-4aee-bd21-8f21c20b8bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\n",
      "fer2013    35340\n",
      "frd2020    31338\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96a62e64-0948-44d1-83fc-0faa24bcb4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add emotion color tags\n",
    "df['color'] = df['emotion'].map(emo_color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d12fdc31-925b-4e59-956c-31f37d0c6ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "Happy       17978\n",
       "Neutral     12396\n",
       "Sad         12154\n",
       "Fear        10242\n",
       "Angry        9906\n",
       "Surprise     4002\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2fabf33-6f2e-40ff-99a0-45200427980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined data\n",
    "df_save_path = os.path.join('data', 'combined_data.csv')\n",
    "df.to_csv(df_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1655d68-ef89-459b-92d5-fc937e146b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skim generates and saves a file with basic descriptives\n",
    "save_path = os.path.join('imgs', f'data_skim.svg')\n",
    "skim_get_figure(df, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92262d81-66d5-4c93-a5cd-000e42caa09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7883353-1ed9-4dbb-99ed-6ebdce7bf834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398335bb-a9ab-47fb-93ea-df3e747f01b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaccb02-d566-418e-9c06-58bddf0c6f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a482f5e-fd8a-4f71-a55f-cbd7f8fe801c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bab44be-3af9-4d17-ab03-0a165b979187",
   "metadata": {},
   "source": [
    "## Pivots grouped by Emotion and Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118b5e8-3612-4c26-b81a-96ded53f4d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skim will generate and save a file with basic descriptives\n",
    "for df_str, pd_df in df_dict.items():\n",
    "    piv_df = emotion_count_piv(\n",
    "        df=pd_df,\n",
    "        gby_cols=['emotion', 'train_test_split'], \n",
    "        agg_col='Filename',\n",
    "        count_cols=['Training', 'Testing']\n",
    "    )\n",
    "\n",
    "    # Skim package for a nice overview, saved to save_path below\n",
    "    out_path = os.path.join('imgs', f'{df_str}_counts_skim.svg')\n",
    "    skim_get_figure(piv_df, save_path=out_path)\n",
    "\n",
    "    # Bar plot of emotion image counts\n",
    "    piv_stacked_bar(df=piv_df, label=df_str)\n",
    "\n",
    "    # Waffle plot of distribution\n",
    "    waffle_path = os.path.join('imgs', f'{df_str}_waffle_chart.png')\n",
    "    waffle_chart(\n",
    "        df=piv_df, group_col='Emotion', data_col='TotalImages', \n",
    "        save_path=waffle_path, display=False, total_squares=100,\n",
    "        color_dict=emo_color_dict\n",
    "    )\n",
    "\n",
    "    # Save pivoted data\n",
    "    intermediate_data_dir = os.path.join('data', 'intermediate_data')\n",
    "    os.makedirs(intermediate_data_dir, exist_ok=True)\n",
    "    piv_save_path = os.path.join(intermediate_data_dir, f'{df_str}_emo_piv.csv')\n",
    "    piv_df.to_csv(piv_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0075ab-5048-49b9-abb1-69a52581468e",
   "metadata": {},
   "source": [
    "## Example Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb0aa6-09af-4e0a-b49f-14fd98fdb72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images=False\n",
    "for df_str, pd_df in df_dict.items():\n",
    "    # Creates image with 1 example face/emotion\n",
    "    fig, axes = show_example_images(\n",
    "        df=pd_df, group_col='emotion', image_col='Full Path', \n",
    "        save_path=f'./imgs/{df_str}_examples_1.png', samples=1,\n",
    "        display=display_images)\n",
    "\n",
    "    # Creates image with 3 example face/emotion\n",
    "    fig, axes = show_example_images(\n",
    "        df=pd_df, group_col='emotion', image_col='Full Path', \n",
    "        save_path=f'./imgs/{df_str}_examples_3.png', samples=3,\n",
    "        display=display_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013711d-d8a2-4b04-8c49-202ae08fe470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
